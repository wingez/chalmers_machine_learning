{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c01c30a",
   "metadata": {},
   "source": [
    "# Uppgift 3 - Bildklassificering \n",
    "\n",
    "I denna uppgiften ska ni testa på att klassificera bilder mha 2 (3) olika tekniker:\n",
    "* SVM - Support vector machines\n",
    "* Fully-connected Neural Network (FC)\n",
    "* Convolutional Neural Network (CNN)\n",
    "\n",
    "Ni ska jämföra resultaten på test-setet utifrån bl.a. hur mycket data som användes för att träna de olika modellerna. Ni ska **kommentera koden** som ni skriver med korta förklaringar på vad koden gör.\n",
    "\n",
    "Datasetet som ni kommer använda er av är ett subset av data från MNIST och innehåller handskrivna siffror från 0-9 i gråskala [0-255]. Datan är uppdelad i två filer, **train.csv** och **test.csv**, som finns tillsammans med uppgiften på Canvas.\n",
    "\n",
    "Till er hjälp så är det meningen att ni ska använda er av följande paket:\n",
    "* torch --- Huvudpaketet för ''pytorch'', används för att implementera och träna neurala nät.\n",
    "* torchvision --- Stödpaket för ''pytorch'', används för att hantera data.\n",
    "* sklearn --- Huvudpaketet för ''scikit-learn'', används för att implementera SVM:s.\n",
    "* matplotlib --- Verktyg för att plotta grafer/bilder.\n",
    "* pandas --- Verktyg för datahantering\n",
    "* numpy --- Verktyg för datahantering/matris-manipulering\n",
    "\n",
    "Paketen kan installeras på olika sätt, exempelvis genom Python-verktyget pip, och det kan då se ut såhär:\n",
    "\n",
    "<pre><code> pip install torch </pre></code>\n",
    "\n",
    "eller\n",
    "\n",
    "<pre><code> pip3 install scikit-learn </pre></code>\n",
    "\n",
    "Vi rekommenderar att ni gör detta i en virtuell Python-miljö via exempelvis Anaconda och med Python-version 3.8.*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c7eed7",
   "metadata": {},
   "source": [
    "Paketen och klasserna som ska importeras är fördefinierade här under."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b84aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffadce06",
   "metadata": {},
   "source": [
    "### Uppgift 1 -  Ladda data\n",
    "\n",
    "1. Ladda in datan från de två filerna med hjälp av **pandas** och spara i varsin DataFrame, train_df & test_df.\n",
    "2. Dela upp träningsdatan i två delar, en för träning och en för validering, genom att specificera storleken på träningsdatan n_training_large. Skapa även en kopia av träningsdatan där endast de första 1000 datapunkterna ingår. Använd samma valideringsdata för alla modeller.\n",
    "3. Ge en kort motivering till varför ni valt just detta värdet på **n_training_large**. \n",
    "4. Ta reda på vilken column i datan som innehåller svaret på vilken klass en bild tillhör och printa det."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceae9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 1.1\n",
    "\n",
    "# Load the two files into dataframes using pandas and store \n",
    "train_df = pd.read_csv(\"train.csv\") # CODE HERE\n",
    "test_df = pd.read_csv(\"test.csv\")  # CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a13b2f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data - small: 1000\n",
      "Training data - large: 23998\n",
      "Validation data: 8000\n",
      "Test data: 10002\n"
     ]
    }
   ],
   "source": [
    "# Uppgift 1.2\n",
    "\n",
    "# Separate the data into a suitable split between training and validation\n",
    "# by specifing the number of samples in the training set, n_training_data.\n",
    "n_training_small = 1000\n",
    "n_training_large = len(train_df) * 3//4\n",
    "\n",
    "\n",
    "print('Training data - small: {}'.format(n_training_small))\n",
    "print('Training data - large: {}'.format(n_training_large))\n",
    "print('Validation data: {}'.format(len(train_df) - n_training_large))\n",
    "print('Test data: {}'.format(len(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cc3f70",
   "metadata": {},
   "source": [
    "Ge en kort motivering till valet av storleken på **n_training_large**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41a1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 1.3\n",
    "# ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad126cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code separates the data into two parts according to the size of the training data, n_training_large & n_training_small,\n",
    "# specified above.\n",
    "val_df = train_df.iloc[n_training_large:, :].copy()\n",
    "train_df_small = train_df.iloc[0:n_training_small, :].copy()\n",
    "train_df = train_df.iloc[0:n_training_large, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01ceb061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23998, 785)\n",
      "(1000, 785)\n",
      "(0, 785)\n",
      "(10002, 785)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the data\n",
    "print(train_df.shape)\n",
    "print(train_df_small.shape)\n",
    "print(val_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3016f5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        4\n",
       "4        0\n",
       "        ..\n",
       "23993    9\n",
       "23994    6\n",
       "23995    7\n",
       "23996    3\n",
       "23997    9\n",
       "Name: label, Length: 23998, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uppgift 1.4\n",
    "\n",
    "# Figure out which column that contains the labels (classes) and print it he\n",
    "train_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611d67d",
   "metadata": {},
   "source": [
    "### Uppgift 2 - Formatera data\n",
    "\n",
    "Kod för att bearbeta data kan snabbt bli rörig och svår att underhålla och bör därför inte hänga ihop med koden som tränar nätverken. Detta ger också bättre läsbarhet och ökad modularitet. PyTorch tillhandahåller två hjälp-klasser: **torch.utils.data.DataLoader** och **torch.utils.data.Dataset** som låter dig ladda in färdiga dataset samt skapa egna. Klassen **Dataset** lagrar datapunkterna och deras motsvarande labels och **DataLoader** gör om datasetet till en *iterable* för att göra det enkelt att använda datapunkterna. I koden i blocket nedan så ser ni skelettet till ett egenskapat dataset, **MNISTDataset**, som ärver klassen **Dataset**. \n",
    "\n",
    "\n",
    "1. Gör klart implementationen av Dataset-klassen **MNISTDataset** genom att skriva kod som separerar datan i labels och features samt normaliserar datan och gör om den till matriser som motsvarar bilder av storleken 28x28 pixlar.\n",
    "2. Skapa 4 dataset utifrån train_df, train_df_small, val_df och test_df.\n",
    "3. Bestäm storlekarna på batcherna som ska användas vid träning respektive testning och skapa 4 DataLoaders för de fyra dataseten ovan. Träningsdatan ska slumpas men inte validering och test.\n",
    "4. Plotta ett par exempelbilder och deras labels mha **matplotlib** och DataLoadern för träningssetet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88174aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 2.1\n",
    "\n",
    "class MNISTDataset(Dataset): \n",
    "  def __init__(self, df):\n",
    "    # Separate the labels and the pixel values into the arrays y and x, respectively.\n",
    "    # CODE HERE\n",
    "    y = \n",
    "    x = \n",
    "    \n",
    "    # Normalize the x-values and transform the data into images of size (color channels, width, height), i.e. w(1, 28, 28).\n",
    "    # CODE HERE\n",
    " \n",
    "    # the numpy arrays are converted into tensors that will be used in the training and testing of the network\n",
    "    self.x=torch.tensor(x,dtype=torch.float32)\n",
    "    self.y=torch.tensor(y)\n",
    " \n",
    "  def __len__(self):\n",
    "    # returns the number of samples in the dataset\n",
    "    return len(self.y)\n",
    "   \n",
    "  def __getitem__(self, idx):\n",
    "    # returns a sample from the dataset at the given index idx\n",
    "    return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 2.2\n",
    "\n",
    "# Create four datasets, from the dataframes defined earlier, using the MNISTDataset class\n",
    "train_dataset = \n",
    "train_dataset_small = \n",
    "val_dataset = \n",
    "test_dataset = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3219ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 2.3\n",
    "\n",
    "# Specify the batch_sizes to use for training and testing\n",
    "batch_size_train = \n",
    "batch_size_test = \n",
    "\n",
    "# Create four DataLoaders from the four datasets above. Shuffle the training data but not the others.\n",
    "train_dload = \n",
    "train_dload_small = \n",
    "val_dload = \n",
    "test_dload = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d27937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 2.4\n",
    "\n",
    "# Plot images and labels for a few examples using the DataLoader for the training set.\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9151df",
   "metadata": {},
   "source": [
    "### Uppgift 3 - Bygga dense-nätverk\n",
    "\n",
    "Det första neurala nätverket vi ska skapa är ett så kallat Fully-connected/Dense Neural Network och består därför endast av lager där alla neuroner i ett lager är sammankopplade med alla neuroner från lagret innan. I **pytorch** så kan man skapa sin egen klass för ett nätverk genom att ärva *nn.Module* och implementera en *__ init__()* samt en *forward()* metod.\n",
    "\n",
    "Ett lager av typen FC skapas i **pytorch** med hjälp av *nn.Linear* enligt exemplet nedan. \n",
    "<pre><code> nn.Linear(nr_of_input_neurons, nr_of_output_neurons) </pre></code>\n",
    "De viktigaste input-parametrarna är antalet neuroner i lagret innan, **nr_of_input_neurons**, samt hur många neuroner detta lagret ska ha, **nr_of_output_neurons**. Mer information hittar ni i dokumentationen: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
    "\n",
    "I dokumentationen hittar ni också information om olika aktiveringsfunktioner: https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\n",
    "\n",
    "När nätverket är färdigt så är nästa steg att bestämma sin loss-funktion samt learning rate och optimerare.\n",
    "\n",
    "1. Gör klart nätverket.\n",
    "2. Välj loss-funktion, learning rate och optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86857b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 3.1\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, input_size=784, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        # Add more Linear (FC/Dense) layers here and experiment with different number of neurons.\n",
    "        self.fc_in = nn.Linear(input_size, 8)\n",
    "        self.fc_out = nn.Linear(self.fc_in.out_features, num_classes)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshapes the input of size (batch x 1x28x28) into a vector (batch x784)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = self.fc_in(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c1f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network\n",
    "dense_net = DenseNet()\n",
    "\n",
    "# Printing the network gives an overview of the network structure\n",
    "print(dense_net)\n",
    "# and calculating the nuber of parameters gives the size of the network\n",
    "print('Number of parameters: {}'.format(sum([param.nelement() for param in dense_net.parameters()])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce97dfde",
   "metadata": {},
   "source": [
    "Bestäm en learning rate, vilken loss-funktion samt vilken optimerare som ska användas för att lösa uppgiften.\n",
    "\n",
    "Loss-funktioner hittar man i modulen **nn** på följande sätt: \n",
    "\n",
    "<pre><code> nn.NamnetPåLossFunktionen() </pre></code>\n",
    "\n",
    "där de olika varianterna hittas här https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "\n",
    "och optimerare:\n",
    "\n",
    "<pre><code> optim.NamnetPåOptimeraren() </pre></code>\n",
    "\n",
    "som hittas här https://pytorch.org/docs/stable/optim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c265902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 3.2\n",
    "\n",
    "learning_rate = \n",
    "\n",
    "loss_function = \n",
    "optimizer = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2703f6",
   "metadata": {},
   "source": [
    "### Uppgift 4 - Träna och evaluera dense-nätverk\n",
    "\n",
    "Träning av nätverket innebär att vi i epoker (upprepade omgångar) låter nätverket gissa klassen på samtliga våra bilder i träningsdatan. Felet och dess gradienterna för samtliga parametrar beräknas mha loss-funktionen och nätverket uppdateras sen utifrån gradienterna av optimeraren.\n",
    "\n",
    "1. Skriv en funktion *train(network, epoch, dataset)* som tar emot nätverket, numret på en epok samt träningsdata och utför träning av nätverket i batcher tills all data har gåtts igenom en gång. Beräkna gradienterna och uppdatera värdet.\n",
    "2. Skriv en funktion *test(dataset)* som beräknar average loss och accuracy för nätverket på ett angivet dataset och sedan printar detta. Funktionen ska returnera snitt-felet som ett värde.\n",
    "3. Experimentera er fram till ett nätverk som presterar bra (>96% accuracy) på det stora träningssetet och jämför sedan resultatet med en kopia av samma nätverk som man tränar om med det lilla datasetet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23f2ee",
   "metadata": {},
   "source": [
    "Nedan följer en beskrivning i text av vad *train* ska göra:\n",
    "\n",
    "<pre><code> \n",
    "funktion train(network, epoch, dataset)\n",
    "    Sätt nätverket i träningsläge\n",
    "    För varje batch i datasetet\n",
    "        Nollställ optimerarens gradienter    \n",
    "        Beräkna nätverkets gissningar utifrån batchen med data\n",
    "        Beräkna felet mha loss-funktionen och true-labels/targets\n",
    "        Beräkna fel-gradienterna för samtliga parametrar\n",
    "        Uppdatera nätverket mha optimeraren\n",
    "        \n",
    "        För vissa batcher, printa info om hur träningen går, exempelvis batch, loss och procent av epoken som är klar.\n",
    "</pre></code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ebed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 4.1\n",
    "\n",
    "def train(network, epoch, dataset):\n",
    "    raise NotImplementedError('Function not implemented yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550fee5",
   "metadata": {},
   "source": [
    "Nedan följer en beskrivning i text av vad *test* ska göra:\n",
    "\n",
    "<pre><code> \n",
    "funktion test(network, dataset)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    Sätt nätverket i evalueringsläge\n",
    "    Stäng av användningen av gradienter\n",
    "        För varje batch i datasetet\n",
    "            Beräkna nätverkets gissningar utifrån batchen med data\n",
    "            Beräkna felet mha loss-funktionen och true-labels/targets\n",
    "            Spara gissningarna i y_pred\n",
    "            Spara de rätta svaren i y_true\n",
    "            \n",
    "    Använd y_pred och y_true för att beräkna accuracy och skapa en confusion matrix\n",
    "    Printa Avg. loss, accuracy och en confusion matrix\n",
    "    Returnera Avg. loss\n",
    "</pre></code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5aea85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uppgift 4.2\n",
    "\n",
    "def test(network, dataset):\n",
    "    raise NotImplementedError('Function not implemented yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b927c",
   "metadata": {},
   "source": [
    "Det som är kvar nu är att träna nätverket i flera omgångar (epoker) och kontinuerligt utvärdera hur träningen går mha valideringsdatan. Varje gång en ny lägsta (bästa) loss uppnås så kan modellen och optimeraren sparas för att användas igen senare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = \n",
    "net_filename = \n",
    "opti_filename = \n",
    "best_loss = 10 ** 4\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # Perform training once on the entire set of training data\n",
    "    train(dense_net, epoch, train_dload)  \n",
    "    \n",
    "    # Evaluate the net using validation data\n",
    "    val_loss = test(dense_net, val_dload)\n",
    "    \n",
    "    # If the latest training yielded a lower validation loss than ever before, save the model to file such that the best one\n",
    "    # can always be retrieved afterwards. \n",
    "    if val_loss < best_loss:\n",
    "        print('Saving best model to {}\\n'.format('./results/{}.pth'.format(net_filename)))\n",
    "        \n",
    "        # Save the network\n",
    "        torch.save(dense_net.state_dict(), './results/{}.pth'.format(net_filename))\n",
    "        # Save the optimizer, in case we want to continue training later\n",
    "        torch.save(optimizer.state_dict(), './results/{}.pth'.format(opti_filename))\n",
    "        # Update the best loss to the current loss\n",
    "        best_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c46688c",
   "metadata": {},
   "source": [
    "Ett sparat nätverk kan sedan laddas in med *torch.load(filename)* enligt koden nedan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204441cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_net = DenseNet()\n",
    "net_filename = \n",
    "\n",
    "network_state_dict = torch.load('./results/{}.pth'.format(net_filename))\n",
    "dense_net.load_state_dict(network_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d10a42",
   "metadata": {},
   "source": [
    "##### Uppgift 4.3\n",
    "Experimentera er fram till ett nätverk som presterar bra (>96% accuracy) på det stora träningssetet genom att uppdatera och ändra nätverket i uppgift 3.1\n",
    "\n",
    "Jämför sedan resultatet med en kopia av samma nätverk som man tränar om med det lilla datasetet. Printa båda nätverkens accuracy och deras respektive confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bcd81",
   "metadata": {},
   "source": [
    "### Uppgift 5 - Träna och evaluera SVM:s\n",
    "\n",
    "1. När vi tränar SVM:s mha scikit-learn så kan vi inte längre använda oss av våra DataLoaders utan behöver därför gå tillbaka till våra dataframes, train_df, train_df_small, val_df och test_df. Skriv kod som separerar varje dataframe i features (pixlar) och labels (klasser) samt normaliserar features [0, 1].\n",
    "2. Skriv kod för att med hjälp av sklearn och klassen SVC skapa en SVM-modell för bildklassificering.\n",
    "3. Träna SVM-modellen på träningsdatan.\n",
    "4. Experimentera er fram till en SVM-modell som presterar bra (>95% accuracy) på det stora träningssetet och jämför sedan resultatet med en kopia av samma nätverk som man tränar om med det lilla datasetet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90086ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 5.1\n",
    "\n",
    "train_y = \n",
    "train_X = \n",
    "\n",
    "train_y_small = \n",
    "train_X_small = \n",
    "\n",
    "val_y = \n",
    "val_X = \n",
    "\n",
    "test_y = \n",
    "test_X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fdf416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 5.2\n",
    "# CODE HERE\n",
    "svm_model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 5.3\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svm_model(model, testX, testy):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(testX)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = metrics.accuracy_score(y_true=testy, y_pred=y_pred)\n",
    "    # Create confusion matrix\n",
    "    cm = metrics.confusion_matrix(testy, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", round(acc, 4) * 100, \"\\n\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c615fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_svm_model(svm_model, val_X, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e096662",
   "metadata": {},
   "source": [
    "##### Uppgift 5.4\n",
    "Experimentera er fram till en SVM-modell som presterar bra (>95% accuracy) på det stora träningssetet genom att uppdatera och ändra modellen i Uppgift 5.2.\n",
    "\n",
    "Jämför sedan resultatet med en kopia av samma modell som man tränar om med det lilla datasetet. Printa båda modellernas accuracy och deras respektive confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c365e",
   "metadata": {},
   "source": [
    "### Uppgift 6 - Träna och evaluera CNN\n",
    "\n",
    "Den sista delen av den här inlämningen är att ni ska implementera och utvärdera ett CNN utifrån de verktyg ni har använt tidigare under uppgiften. En viktig skillnad med convolutions jämfört med FC-lager är att de gradvis minskar storleken på sin output utifrån kernel-size:n (n, m) och att antalet kanaler/channels motsvarar antalet filter i lagret. Exempelvis så kommer en input på 28x28 som körs genom en convolution med kernel-size (3, 4) och stride=1 ge en output som är (28-n+1)x(28-m+1)=26x25. Använder man däremot padding när man genomför sina convolutions så blir input och output lika stora.\n",
    "\n",
    "I pytorch genomför man convolutions mha:\n",
    "<pre><code> nn.Conv2d(nr_of_input_filters, nr_of_output_filters, kernel) </pre></code>\n",
    "\n",
    "För mer information se dokumentationen: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
    "\n",
    "1. Gör klart implementationen av ett CNN\n",
    "2. Experimentera fram ett CNN-nätverk som presterar minst lika bra som Dense-nätet.\n",
    "3. Jämför sedan resultatet med en kopia av samma modell som man tränar om med det lilla datasetet. Printa båda modellernas accuracy och deras respektive confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.kernel = \n",
    "        self.filters = \n",
    "\n",
    "        self.conv_in = nn.Conv2d(input_channels, self.filters, self.kernel)\n",
    "        self.activation = \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_net = ConvModel()\n",
    "print(conv_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uppgift 6.2\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3224163",
   "metadata": {},
   "source": [
    "### Uppgift 7 - Jämför restultaten på test-setet\n",
    "\n",
    "Gör en jämförelse av de tre sätten att klassificera på utifrån de resultat ni har fått på test-setet, både för det stora och det lilla setet med träningsdata. Komplettera er jämförelse med grafer, resultat, kod eller annat som stärker er argumentation i första rutan nedan och skriv en kort beskrivning av era slutsatser i rutan under det."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a2272",
   "metadata": {},
   "source": [
    "### Uppgift 8 - Ungefär hur många timmar har gruppen lagt på att göra klart inlämningen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}